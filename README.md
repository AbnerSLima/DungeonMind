<<<<<<< HEAD

# DungeonMind - Explorador de Masmorra com InteligÃªncia Artificial

## ðŸ’¡ Ideia do Projeto

O DungeonMind Ã© um projeto educacional que combina jogos e inteligÃªncia artificial. O objetivo Ã© treinar um agente para explorar uma masmorra, encontrar tesouros e evitar armadilhas usando algoritmos de aprendizado por reforÃ§o.

## âœ¨ Funcionalidades e AlteraÃ§Ãµes

- Ambiente personalizado baseado em uma grade (dungeon).
- Treinamento de agente com Q-Learning.
- VisualizaÃ§Ã£o do ambiente com Pygame.
- RenderizaÃ§Ã£o do ambiente e estados do agente.
- IntegraÃ§Ã£o entre IA e interface grÃ¡fica.

## ðŸ§  Como Treinar e Testar o Agente

### Treinar o Agente

```bash
python -m IA.train
```

### Executar o Jogo com Controle Manual (Setas)

```bash
python main.py
```

## ðŸ“š Bibliotecas Utilizadas

- `numpy`
- `pygame`
- `gym`

## âš™ï¸ Algoritmo Aplicado

- Q-Learning (Aprendizado por ReforÃ§o)
  - PolÃ­tica epsilon-greedy
  - Tabela Q-Table com atualizaÃ§Ãµes iterativas

## ðŸ“ CÃ¡lculos Realizados

- AtualizaÃ§Ã£o da Q-table:
  ```python
  Q[state, action] = (1 - alpha) * Q[state, action] + alpha * (reward + gamma * np.max(Q[new_state]))
  ```
- CÃ¡lculo de recompensa com base em eventos (tesouro, armadilha, saÃ­da).

## ðŸš§ Dificuldades Encontradas

- IntegraÃ§Ã£o entre ambiente de IA e visualizaÃ§Ã£o com Pygame.
- Tratamento de aÃ§Ãµes invÃ¡lidas nas bordas da masmorra.
- Controle de exibiÃ§Ã£o e lÃ³gica de eventos.

## ðŸ“Š Resultados Obtidos

- Treinamento mostra aumento progressivo da recompensa mÃ©dia.
- Agente aprende a evitar armadilhas e alcanÃ§ar a saÃ­da eficientemente.
- Pode ser estendido para nÃ­veis mais complexos, mÃºltiplos inimigos e obstÃ¡culos dinÃ¢micos.

---

Criado para fins acadÃªmicos na disciplina de Aprendizado de MÃ¡quina.
=======

# DungeonMind - Explorador de Masmorra com InteligÃªncia Artificial

## ðŸ’¡ Ideia do Projeto

O DungeonMind Ã© um projeto educacional que combina jogos e inteligÃªncia artificial. O objetivo Ã© treinar um agente para explorar uma masmorra, encontrar tesouros e evitar armadilhas usando algoritmos de aprendizado por reforÃ§o.

## âœ¨ Funcionalidades e AlteraÃ§Ãµes

- Ambiente personalizado baseado em uma grade (dungeon).
- Treinamento de agente com Q-Learning.
- VisualizaÃ§Ã£o do ambiente com Pygame.
- RenderizaÃ§Ã£o do ambiente e estados do agente.
- IntegraÃ§Ã£o entre IA e interface grÃ¡fica.

## ðŸ§  Como Treinar e Testar o Agente

### Treinar o Agente

```bash
python -m IA.train
```

### Executar o Jogo com Controle Manual (Setas)

```bash
python main.py
```

## ðŸ“š Bibliotecas Utilizadas

- `numpy`
- `pygame`
- `gym`

## âš™ï¸ Algoritmo Aplicado

- Q-Learning (Aprendizado por ReforÃ§o)
  - PolÃ­tica epsilon-greedy
  - Tabela Q-Table com atualizaÃ§Ãµes iterativas

## ðŸ“ CÃ¡lculos Realizados

- AtualizaÃ§Ã£o da Q-table:
  ```python
  Q[state, action] = (1 - alpha) * Q[state, action] + alpha * (reward + gamma * np.max(Q[new_state]))
  ```
- CÃ¡lculo de recompensa com base em eventos (tesouro, armadilha, saÃ­da).

## ðŸš§ Dificuldades Encontradas

- IntegraÃ§Ã£o entre ambiente de IA e visualizaÃ§Ã£o com Pygame.
- Tratamento de aÃ§Ãµes invÃ¡lidas nas bordas da masmorra.
- Controle de exibiÃ§Ã£o e lÃ³gica de eventos.

## ðŸ“Š Resultados Obtidos

- Treinamento mostra aumento progressivo da recompensa mÃ©dia.
- Agente aprende a evitar armadilhas e alcanÃ§ar a saÃ­da eficientemente.
- Pode ser estendido para nÃ­veis mais complexos, mÃºltiplos inimigos e obstÃ¡culos dinÃ¢micos.

---

Criado para fins acadÃªmicos na disciplina de Aprendizado de MÃ¡quina.
>>>>>>> b6f05890cf34dcf5b2495004601b651395be2be4
